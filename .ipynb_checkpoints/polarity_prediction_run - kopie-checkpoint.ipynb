{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import library as l\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16376\n"
     ]
    }
   ],
   "source": [
    "file='aggressive_dedup.json'\n",
    "size = 40000\n",
    "topsize = 300\n",
    "\n",
    "seed1 = np.random.randint(size)\n",
    "print(seed1)\n",
    "#seed2 = np.random.randint(size)\n",
    "today = datetime.date.today()\n",
    "\n",
    "savestring = 'seed_' + str(seed1) + '_size_' + str(size) + '_topsize_' + str(topsize) + '_date_' + str(today)\n",
    "\n",
    "if not os.path.exists(savestring):\n",
    "    os.makedirs(savestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, time, ratings, seen, indices = l.get_data(year='2001', size=size, limit=100000000)\n",
    "\n",
    "l.save_file(savestring + '/indices.data', indices)\n",
    "l.save_file(savestring + '/seen.data', seen)\n",
    "\n",
    "l.simplify_ratings(data, ratings)\n",
    "l.save_file(savestring + '/ratings.data', ratings)\n",
    "\n",
    "#data2 = l.stopwords_filter(data)\n",
    "\n",
    "l.selection_print(data, ratings)\n",
    "\n",
    "x = sorted(list(data.keys()))\n",
    "y = [seen.get(yr) for yr in x]\n",
    "print(x, y)\n",
    "plt.bar(x, y)\n",
    "plt.show()\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "LR = LogisticRegression(penalty='l1', n_jobs=-1, solver='saga', max_iter=300)\n",
    "#LR = LogisticRegression(penalty='l1', n_jobs=-1, solver='saga', max_iter=100, class_weight='balanced')\n",
    "\n",
    "CV = CountVectorizer(ngram_range=(1,2), analyzer='word', min_df=5, max_features=5000)\n",
    "\n",
    "features = []\n",
    "x = sorted(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873875\n",
      "2001\n",
      "f1: [0.62448828 0.92420942]\n",
      "recall: [0.54693611 0.95143829]\n",
      "precision: [0.72766696 0.89849569]\n",
      "\n",
      "0.863\n",
      "2002\n",
      "f1: [0.6162465  0.91661595]\n",
      "recall: [0.54556727 0.94316581]\n",
      "precision: [0.7079646  0.89151991]\n",
      "\n",
      "0.855625\n",
      "2003\n",
      "f1: [0.61202553 0.91131076]\n",
      "recall: [0.54813478 0.93625749]\n",
      "precision: [0.69277567 0.88765894]\n",
      "\n",
      "0.843125\n",
      "2004\n",
      "f1: [0.60447526 0.90215951]\n",
      "recall: [0.53876404 0.93022508]\n",
      "precision: [0.68844221 0.87573785]\n",
      "\n",
      "0.832875\n",
      "2005\n",
      "f1: [0.60894999 0.89372864]\n",
      "recall: [0.5205 0.937 ]\n",
      "precision: [0.73361522 0.85427747]\n",
      "\n",
      "0.84675\n",
      "2006\n",
      "f1: [0.61470773 0.90435325]\n",
      "recall: [0.53181077 0.94075637]\n",
      "precision: [0.7282204  0.87066246]\n",
      "\n",
      "0.85975\n",
      "2007\n",
      "f1: [0.60933148 0.91453382]\n",
      "recall: [0.52934059 0.94580117]\n",
      "precision: [0.71780148 0.88526766]\n",
      "\n",
      "0.852\n",
      "2008\n",
      "f1: [0.61904762 0.9081601 ]\n",
      "recall: [0.53266888 0.94510817]\n",
      "precision: [0.73886329 0.87399224]\n",
      "\n",
      "0.8475\n",
      "2009\n",
      "f1: [0.62438424 0.90432873]\n",
      "recall: [0.55531216 0.93391642]\n",
      "precision: [0.71308017 0.87655822]\n",
      "\n",
      "0.846625\n",
      "2010\n",
      "f1: [0.62919311 0.90331731]\n",
      "recall: [0.55196182 0.93752044]\n",
      "precision: [0.73155306 0.87152197]\n",
      "\n",
      "0.830375\n",
      "2011\n",
      "f1: [0.61061693 0.89157012]\n",
      "recall: [0.532      0.92983333]\n",
      "precision: [0.71649832 0.85633154]\n",
      "\n",
      "0.849125\n",
      "2012\n",
      "f1: [0.62174867 0.90576938]\n",
      "recall: [0.54030501 0.94110967]\n",
      "precision: [0.73210332 0.87298721]\n",
      "\n",
      "0.87025\n",
      "2013\n",
      "f1: [0.65423051 0.92014156]\n",
      "recall: [0.57900943 0.94860406]\n",
      "precision: [0.75191424 0.89333732]\n",
      "\n",
      "0.861\n",
      "2014\n",
      "f1: [0.63778502 0.91399845]\n",
      "recall: [0.56296722 0.94377895]\n",
      "precision: [0.73553719 0.88603989]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(x):\n",
    "    LR, CV = l.predict_scores(data[key], ratings[key], CV, LR, i, key, savestring, features)\n",
    "    \n",
    "    if i == 0:\n",
    "        top_f = [[x,[len(features)-i]] for i, (_,x) in enumerate(sorted(zip(LR.coef_[0],features)))][:(-topsize - 1):-1]\n",
    "        bot_f = [[x,[i+1]] for i, (_,x) in enumerate(sorted(zip(LR.coef_[0],features)))][:topsize]\n",
    "    else:\n",
    "        for i, m in enumerate(top_f):\n",
    "            top_f[i][1] += [len(features)-i for i, (_,x) in enumerate(sorted(zip(LR.coef_[0],features))) if x == m[0]]\n",
    "        for i, m in enumerate(bot_f):\n",
    "            bot_f[i][1] += ([i+1 for i, (_,x) in enumerate(sorted(zip(LR.coef_[0],features))) if x == m[0]])\n",
    "\n",
    "l.save_file(savestring + '/top_f.data', top_f)\n",
    "l.save_file(savestring + '/bot_f.data', bot_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
